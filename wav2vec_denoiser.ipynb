{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/hydra/core/plugins.py:225: UserWarning: \n",
      "\tError importing 'hydra_plugins.hydra_colorlog'.\n",
      "\tPlugin is incompatible with this Hydra version or buggy.\n",
      "\tRecommended to uninstall or upgrade plugin.\n",
      "\t\tImportError : cannot import name 'SearchPathPlugin' from 'hydra.plugins' (/usr/local/lib/python3.10/dist-packages/hydra/plugins/__init__.py)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from types import MethodType\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from evaluate import load\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "from undecorated import undecorated\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from dasr.models.facebook_denoiser import get_pretrained_model\n",
    "\n",
    "\n",
    "def normalize_text(text: str):\n",
    "    for char in [\".\", \",\", \"!\", \"?\", \"(\", \")\"]:\n",
    "        text = text.replace(char, \" \")\n",
    "    text = text.replace(\"ё\", \"е\")\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "import os\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
    "os.environ[\"NUMBA_CACHE_DIR\"] = \"/tmp/\"\n",
    "\n",
    "with initialize(version_base=None, config_path=\"configs\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "    \n",
    "cfg.data.batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "# path_model = \"jonatasgrosman/wav2vec2-xls-r-1b-russian\"\n",
    "path_model = \"jonatasgrosman/wav2vec2-large-xlsr-53-russian\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(path_model)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(path_model)\n",
    "model.to(device)\n",
    "\n",
    "denoiser = get_pretrained_model(\"dns64\").to(device)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading datasets\n",
      "Train dataset loaded\n",
      "Test dataset loaded\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = instantiate(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clean_audios': tensor([[-1.8190e-12, -5.4570e-12, -2.9104e-11,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-6.1062e-16, -1.9429e-16,  1.3878e-16,  ..., -3.6380e-12,\n",
       "          -7.2760e-12,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-8.1855e-12,  5.4570e-12, -1.0914e-11,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]),\n",
       " 'noise_audios': tensor([[ 0.0260,  0.0118,  0.0027,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0295,  0.0043,  0.0102,  ..., -0.0046, -0.0149,  0.0048],\n",
       "         [ 0.0143,  0.0060, -0.0099,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0166, -0.0262, -0.0253,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " 'clean_attention_masks': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
       " 'noise_attention_masks': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
       " 'transcriptions': ['К сожалению, эти предложения не нашли отражения в тексте.',\n",
       "  'Если не будет возражений, я буду считать, что Ассамблея согласна с этим предложением.',\n",
       "  'Новошахтинск — милый город',\n",
       "  'Мы особенно рады отметить, что число скрывающихся от правосудия лиц уменьшилось.']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_sentences = []\n",
    "all_target_sentences = []\n",
    "\n",
    "for batch in test_loader:\n",
    "\n",
    "    speech = batch[\"noise_audios\"].to(device)\n",
    "\n",
    "    denoisy_speech = denoiser(speech).squeeze(1)\n",
    "\n",
    "    inputs = processor(denoisy_speech, sampling_rate=16_000, return_tensors=\"pt\", padding=True, do_normalize=True)\n",
    "    attention_mask = batch[\"noise_attention_masks\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.squeeze(0).to(device), attention_mask=attention_mask.to(device)).logits\n",
    "        # logits = model(inputs.input_values.squeeze(0).to(device)).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "    all_predicted_sentences.extend(predicted_sentences) \n",
    "    all_target_sentences.extend(batch[\"transcriptions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.text import WordErrorRate, CharErrorRate\n",
    "\n",
    "wer = WordErrorRate()\n",
    "cer = CharErrorRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5798), tensor(0.2800))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predicted_sentences = [normalize_text(sentence) for sentence in all_predicted_sentences]\n",
    "all_target_sentences = [normalize_text(sentence) for sentence in all_target_sentences]\n",
    "\n",
    "wer(preds=all_predicted_sentences, target=all_target_sentences), cer(preds=all_predicted_sentences, target=all_target_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
