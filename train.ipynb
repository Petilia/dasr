{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.24.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from hydra.utils import instantiate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dasr.train.utils import sum_list_dicts\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.device = cfg.device\n",
    "        self.model = instantiate(cfg.denoiser)\n",
    "        assert (\n",
    "            self.model(torch.randn(1, 3000)).shape[-1] == torch.randn(1, 3000).shape[-1]\n",
    "        ), \"input_dim != output_dim\"\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = instantiate(\n",
    "            cfg.train.optimizer, params=self.model.parameters()\n",
    "        )\n",
    "\n",
    "        self.asr = instantiate(cfg.asr)\n",
    "        self.asr_metric = cfg.asr.asr_metric\n",
    "\n",
    "        self.train_loader, self.test_loader = instantiate(cfg.data)\n",
    "\n",
    "        # define loss\n",
    "        self.add_loss = instantiate(cfg.loss)\n",
    "        self.add_loss.to(self.device)\n",
    "\n",
    "        self.n_epoch_before_asr_loss = cfg.train.n_epoch_before_asr_loss\n",
    "        self.asr_loss_coef = cfg.train.asr_loss_coef\n",
    "        self.only_asr_loss = cfg.train.only_asr_loss\n",
    "        if self.only_asr_loss:\n",
    "            self.n_epoch_before_asr_loss = 0\n",
    "\n",
    "        self.logger = instantiate(cfg.wandb)\n",
    "        self.checkpoints_dir = Path(\n",
    "            f\"checkpoints/{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}_{cfg.wandb.run_name}\"\n",
    "        )\n",
    "        os.makedirs(self.checkpoints_dir)\n",
    "\n",
    "        self.n_epoch = cfg.train.n_epoch\n",
    "        self.epoch = 0\n",
    "        self.step = 0\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        self.logger.set_mode(\"train\")\n",
    "\n",
    "        n_ep_it_loss = 50\n",
    "        stats = []\n",
    "        asr_stats = []\n",
    "        for i, batch in tqdm(enumerate(self.train_loader)):\n",
    "            self.optimizer.zero_grad()\n",
    "            gt_transcript = batch[\"transcriptions\"]\n",
    "            clear = batch[\"clean_audios\"].to(self.device)\n",
    "            noisy = batch[\"noise_audios\"].to(self.device)\n",
    "            output = self.model(noisy)\n",
    "            output = output.squeeze(1)\n",
    "\n",
    "            if self.epoch >= self.n_epoch_before_asr_loss:\n",
    "                asr_loss, asr_loss_stats = self.asr.get_loss(\n",
    "                    clear, output, noisy_speech=noisy, gt_transcript=gt_transcript\n",
    "                )\n",
    "                if not self.only_asr_loss:\n",
    "                    asr_loss *= self.asr_loss_coef\n",
    "                    asr_loss.backward(retain_graph=True)\n",
    "                else:\n",
    "                    asr_loss.backward()\n",
    "\n",
    "                asr_stats.append(asr_loss_stats)\n",
    "\n",
    "            if not self.only_asr_loss:\n",
    "                loss, loss_stats = self.add_loss(clear, output)\n",
    "                loss.backward()\n",
    "                stats.append(loss_stats)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if i % n_ep_it_loss == n_ep_it_loss - 1:\n",
    "                stats = sum_list_dicts(stats)\n",
    "                if self.epoch >= self.n_epoch_before_asr_loss:\n",
    "                    asr_stats = sum_list_dicts(asr_stats)\n",
    "                    stats = stats | asr_stats\n",
    "                stats[\"epoch\"] = self.epoch\n",
    "                self.logger.log_dict(stats)\n",
    "                stats = []\n",
    "                asr_stats = []\n",
    "\n",
    "            self.step += 1\n",
    "            self.logger.set_step(self.step)\n",
    "\n",
    "    def eval_epoch(self):\n",
    "        self.model.eval()\n",
    "        self.logger.set_mode(\"val\")\n",
    "\n",
    "        stats = []\n",
    "        asr_stats = []\n",
    "        for batch in tqdm(self.test_loader):\n",
    "            gt_transcript = batch[\"transcriptions\"]\n",
    "            clear = batch[\"clean_audios\"].to(self.device)\n",
    "            noisy = batch[\"noise_audios\"].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                output = self.model(noisy)\n",
    "\n",
    "            output = output.squeeze(1)\n",
    "            _, loss_stats = self.add_loss(clear, output)\n",
    "            asr_loss_stats = self.asr.eval(\n",
    "                clear, output, noisy_speech=noisy, gt_transcript=gt_transcript\n",
    "            )\n",
    "            # print(asr_loss_stats)\n",
    "\n",
    "            stats.append(loss_stats)\n",
    "            asr_stats.append(asr_loss_stats)\n",
    "\n",
    "        stats = sum_list_dicts(stats)\n",
    "        asr_stats = sum_list_dicts(asr_stats)\n",
    "        stats = stats | asr_stats\n",
    "        stats[\"epoch\"] = self.epoch\n",
    "        self.logger.log_dict(stats)\n",
    "        return stats\n",
    "\n",
    "    def eval_iter(self):\n",
    "        self.model.eval()\n",
    "        self.logger.set_mode(\"val\")\n",
    "\n",
    "        batch = next(iter(self.test_loader))\n",
    "        gt_transcript = batch[\"transcriptions\"]\n",
    "        clear = batch[\"clean_audios\"].to(self.device)\n",
    "        noisy = batch[\"noise_audios\"].to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(noisy)\n",
    "\n",
    "        output = output.squeeze(1)\n",
    "        asr_loss_stats = self.asr.eval(\n",
    "            clear, output, noisy_speech=noisy, gt_transcript=gt_transcript\n",
    "        )\n",
    "        return asr_loss_stats\n",
    "\n",
    "    def train(self):\n",
    "        best_val_metric = 1e6\n",
    "        for i in range(self.n_epoch):\n",
    "            self.train_epoch()\n",
    "            torch.cuda.empty_cache()\n",
    "            eval_stats = self.eval_epoch()\n",
    "            torch.cuda.empty_cache()\n",
    "            if eval_stats[f\"{self.asr_metric} (ref-denoisy)\"] < best_val_metric:\n",
    "                best_val_metric = eval_stats[f\"{self.asr_metric} (ref-denoisy)\"]\n",
    "                self.save_weights(best=best_val_metric)\n",
    "            else:\n",
    "                self.save_weights()\n",
    "            self.epoch += 1\n",
    "\n",
    "    def save_weights(self, best=False):\n",
    "        checkpoint_dict = {\n",
    "            \"epoch\": self.epoch,\n",
    "            \"config\": self.cfg,\n",
    "            # \"stats_dict\": stats_dict,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint_dict, self.checkpoints_dir / f\"epoch_{self.epoch}.pth\")\n",
    "\n",
    "        if best:\n",
    "            torch.save(checkpoint_dict, self.checkpoints_dir / \"best.pth\")\n",
    "            print(f\"Metric improved to {best}\")\n",
    "            wandb_log_path = str((self.checkpoints_dir / \"best.pth\").relative_to(\".\"))\n",
    "            self.logger.log_best_model(wandb_log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/hydra/core/plugins.py:225: UserWarning: \n",
      "\tError importing 'hydra_plugins.hydra_colorlog'.\n",
      "\tPlugin is incompatible with this Hydra version or buggy.\n",
      "\tRecommended to uninstall or upgrade plugin.\n",
      "\t\tImportError : cannot import name 'SearchPathPlugin' from 'hydra.plugins' (/usr/local/lib/python3.10/dist-packages/hydra/plugins/__init__.py)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
    "os.environ[\"NUMBA_CACHE_DIR\"] = \"/tmp/\"\n",
    "\n",
    "with initialize(version_base=None, config_path=\"configs\"):\n",
    "    cfg = compose(config_name='config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'denoiser': {'_target_': 'dasr.models.naive_model_lstm.SimpleModelLSTM', 'chin': 1, 'chout': 1, 'depth': 3, 'kernel_size': 8, 'stride': 4, 'causal': True, 'hidden': 48, 'growth': 2, 'max_hidden': 4096, 'normalize': True, 'resample': 1, 'floor': 0.001, 'sample_rate': 16000}, 'asr': {'_target_': 'dasr.asr.whisper.WhisperEnv', 'device': 'cuda', 'path_model': '/home/docker_current/hf_whisper/whisper-base', 'asr_metric': 'cer', 'baseline': 0.7}, 'data': {'_target_': 'dasr.datasets.make_dataloaders.make_loaders', 'common_voice': {'_target_': 'dasr.datasets.common_voice.get_common_voice', 'name': 'mozilla-foundation/common_voice_11_0', 'language': 'ru', 'train_split': 'train[0:3000]', 'test_split': 'test[0:200]', 'removavle_cols': ['accent', 'age', 'client_id', 'down_votes', 'gender', 'locale', 'path', 'segment', 'up_votes'], 'sampling_rate': 16000}, 'batch_size': 5, 'desire_snr_db': 10, 'max_length': False}, 'train': {'optimizer': {'_target_': 'dasr.optimizers.lion.Lion', 'lr': 0.0001}, 'trainer': {'_target_': 'dasr.train.trainer.Trainer'}, 'n_epoch': 200, 'n_epoch_before_asr_loss': 20000, 'only_asr_loss': False, 'asr_loss_coef': 0.2}, 'loss': {'_target_': 'dasr.losses.loss_factory.AdditiveLoss', 'criteria': 'l1', 'use_sfft_loss': True, 'factor_sc': 0.5, 'factor_mag': 0.5}, 'wandb': {'_target_': 'dasr.logger.wandb_logger.WandbLogger', 'project_name': 'dasr', 'run_name': 'SNR=10, train[0:3000], baseline=0.7, without RL, simple_denoiser_lstm'}, 'facebook_denoiser': {'segment': 4}, 'device': 'cuda'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading datasets\n",
      "Train dataset loaded\n",
      "Test dataset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpetili\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/docker_current/dasr/wandb/run-20231028_202422-pj0izsuh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/petili/dasr/runs/pj0izsuh' target=\"_blank\">SNR=10, train[0:3000], baseline=0.7, without RL, simple_denoiser_lstm</a></strong> to <a href='https://wandb.ai/petili/dasr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/petili/dasr' target=\"_blank\">https://wandb.ai/petili/dasr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/petili/dasr/runs/pj0izsuh' target=\"_blank\">https://wandb.ai/petili/dasr/runs/pj0izsuh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WhisperEnv.get_loss of <dasr.asr.whisper.WhisperEnv object at 0x7f2b71fde6b0>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.asr.get_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trainer.train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_transcript = batch[\"transcriptions\"]\n",
    "clear = batch[\"clean_audios\"].to(trainer.device)\n",
    "noisy = batch[\"noise_audios\"].to(trainer.device)\n",
    "\n",
    "output = trainer.model(noisy)\n",
    "output = output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_loss, asr_loss_stats = trainer.asr.get_loss(\n",
    "    clear, output, noisy_speech=noisy, gt_transcript=gt_transcript\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asr_loss': -4.245423793792725,\n",
       " 'reward': -0.1976834088563919,\n",
       " 'logprob': -22.299457550048828,\n",
       " 'wer (ref-denoisy)': 1.0,\n",
       " 'cer (ref-denoisy)': 0.9074626865671642,\n",
       " 'wer (gt-ref)': 0.425531914893617,\n",
       " 'cer (gt-ref)': 0.09467455621301775,\n",
       " 'wer (gt-denoisy)': 1.0,\n",
       " 'cer (gt-denoisy)': 0.8964497041420119,\n",
       " 'wer (gt-noisy)': 0.6382978723404256,\n",
       " 'cer (gt-noisy)': 0.2869822485207101}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr_loss_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
